# Required for downloading gated models on Hugging Face (Meta Llama usually is)
HF_TOKEN=hf_your_token_here

# Choose a model
LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct

# vLLM tuning (lower utilization if you share VRAM with Whisper/TTS)
VLLM_GPU_MEMORY_UTILIZATION=0.55
VLLM_MAX_MODEL_LEN=4096
VLLM_MAX_NUM_SEQS=4
VLLM_MAX_BATCHED_TOKENS=4096

# API limits/tuning
MAX_INPUT_CHARS=300000
CHUNK_CHARS=12000
REQUEST_TIMEOUT_SECS=180
