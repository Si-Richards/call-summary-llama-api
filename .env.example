# Required for downloading gated models on Hugging Face
HF_TOKEN=hf_your_token_here

# Choose a model
LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
#LLM_MODEL=meta-llama/Llama-3.2-1B-Instruct
#LLM_MODEL=meta-llama/Llama-3.2-3B-Instruct

# vLLM tuning
VLLM_GPU_MEMORY_UTILIZATION=0.50
VLLM_MAX_MODEL_LEN=4096
VLLM_MAX_NUM_SEQS=2
VLLM_MAX_BATCHED_TOKENS=4096

# API limits/tuning
MAX_INPUT_CHARS=300000
REQUEST_TIMEOUT_SECS=180

# App-side settings (MUST match VLLM_MAX_MODEL_LEN)
MODEL_MAX_LEN=4096

# In-memory LRU cache size (0 disables caching)
CACHE_SIZE=512
